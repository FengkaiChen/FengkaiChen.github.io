<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Fengkai Chen</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Fengkai Chen</name>
                <div class="site-affilation">
                  <span class="affilation"><ul class="flat">
              <p>I am a master ECE-Robotics student at University of Michigan, Ann Arbor, and currently looking for a responsible full-time Software/Robotics/Self-Driving-related Engineer position starting from May 2023. I am also an advanced engineer intern working at Isuzu Technical Center of America, Inc. (ITCA).
                <p>During my leisure time, I love playing basketball, videos games and watching movies. My favorite movie is The Shawshank Redemption and my favorite game is Dark Soul from Hidetaka Miyazaki.
                <div></div>

              <p style="text-align:center">
                <a href="data/Resume.pdf">Resume</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/fengkai-chen-901872212/">Linkedin</a> &nbsp/&nbsp
                <a href="https://github.com/FengkaiChen/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/JonBarron.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>


            <td style="padding:20px;width:100%;vertical-align:middle">

              <heading>Education</heading>
              <p>
            	<div class="site-affilation">
                <span class="affilation"><ul class="flat">
                    <li class="name">Master of Science (M.Sc.) in Electrical and Computer Engineering (ECE), University of Michigan, Ann Arbor</li>
                    <li class="name">Bachelor of Engineering (B.Eng.) in Electrical Engineering (EE), Zhejiang University</li>
                    <li class="name">Bachelor of Science (B.Sc.) in Electrical Engineering (EE), University of Illinois, Urbana-Champaign </li>
                  </ul></span>
                </p>
              </div>
              <br>
              <br>

              <heading>Experience</heading>
              <div>
                    <img src="images/isuzu.png" style="vertical-align:middle;" width="100">
                     <span><font size="4">Advanced Engineer Intern</font>  <font size="2">(02/03/2023 - Present)</font></span>
                 </div>
                <li class="name">Integrate autonomous driving software stack with simulation software.</li>
                <li class="name">Validate and correlate between simulation and testing.</li>
                <li class="name">Support virtual development and CI/CD Jenkins pipeline building.</li>

                <div>
                  <img src="images/zhongheng.jpeg" style="vertical-align:middle;" width="100">
                   <span><font size="4">Hardware Engineer Intern</font>  <font size="2">(06/01/2020 - 08/31/2020)</font></span>
               </div>
              <li class="name">Carried out the design and test of power monitor product.</li>
              <li class="name">Validate the I/O waveform and ripple tex.</li>
              <li class="name">Fullfilled EMC tests on product comminication board.</li>
              <br>
              <br>
              <heading>Research & Projects</heading>
              
                My research interest lies in mobile robotics, machine learning, deep learning and computer vision. Most of my research is about robotics and deep learning for computer vision.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="malle_stop()" onmouseover="malle_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:40%;vertical-align:middle">
              <div class="one">
                <div class="two" id='malle_image'>
                  <img src='images/fig3.png' width="300"></div>
                <img src='images/husky.png' width="300">
              </div>
              <script type="text/javascript">
                function malle_start() {
                  document.getElementById('malle_image').style.opacity = "1";
                }

                function malle_stop() {
                  document.getElementById('malle_image').style.opacity = "0";
                }
                malle_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a>
                <papertitle>Ranking Inversement Learning & Incrementally-exploring Information Gathering</papertitle>
              </a>
              <br>
              <strong>Fengkai Chen</strong>,
              <a>Sangli Teng</a>,
              <a>Maani Ghaffari</a>
              <p></p>
              <p>
                Information gathering is an critical and broadly studied task for mobile robotics operating in unknown environments. Incrementally-exploring information Gathering(IIG) algorithm takes a dense stochastic map of enviroment to collect information for exploration. While the information gathering process is time-consuming and unstable, we proposed a new information collect method which apply Inverse Reinforcement Learning(IRL). The IRL  incorporates both exteroceptive and proprioceptive sensory data, and generate a reward map  to replace original information of IIG exploration. The IRL will be trained on human demonstration in advance, and the inference process is sufficiently efficient.
              </p>
            </td>
          </tr>
					
          <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:40%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfsuper_image'><video  width=190% height=190% muted autoplay loop>
                <source src="images/garage_garage_short.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/Intro.png' width="300">
              </div>
              <script type="text/javascript">
                function nerfsuper_start() {
                  document.getElementById('nerfsuper_image').style.opacity = "1";
                }

                function nerfsuper_stop() {
                  document.getElementById('nerfsuper_image').style.opacity = "0";
                }
                nerfsuper_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a>
                <papertitle>Online Map Recognition using Bayesian Updates</papertitle>
              </a>
              <br> 
              <strong>Fengkai Chen</strong>,
              <a>Jake Olkin</a>, 
              <a>Cameron Kisailus</a>,
              <a>Tianyang Shi</a>,
              <a>Sihang Wei</a>
              <br>

							<a href="data/Online Map Recognition using Bayesian Updates.pdf">PDF</a> / 
							<a href="https://www.youtube.com/watch?v=pzFOLR6G_VE&t=142s">video</a> /
							<a href="https://github.com/camkisailus/ROB530_FinalProject">code</a> / 
							<a href="https://colab.research.google.com/drive/1jvaOu-FcIKEyTYHuewVoGX_3eTZra149">colab</a>				
              <p></p>
              <p>In order to reliably deploy robots in large-scale environments, it is fundamental for robots to have accurate localization. Robot relocalization is the act of determining the position in a robot in a previously mapped environment. Relocalization in small-scale environments is usually done by maintaining a contiguous map of the entire environment, but this does not scale. Methods to combat this scaling problem have proposed splitting large, global maps into smaller metrical maps. However, this adds another dimension to the relocalization problem, since the algorithm must additionally determine which map is it located on. Probabilistic localization algorithms are governed by the total law of probability, so it is impossible to indicate low, or even zero, belief a robot is anywhere on a given map (i.e. a particle filter will always maintain some belief of the robot location)</p>
            </td>
          </tr>

          <tr onmouseout="p_stop()" onmouseover="p_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:40%;vertical-align:middle">
              <div class="one">
                <div class="two" id='project3'>
                  <img src='images/fig2.png' width="300"></div>
                <img src='images/fig4.png' width="300">
              </div>
              <script type="text/javascript">
                function p_start() {
                  document.getElementById('project3').style.opacity = "1";
                }

                function p_stop() {
                  document.getElementById('project3').style.opacity = "0";
                }
                p_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
			          <a>
			            <papertitle>3D Human Pose Detection and Estimation in Multi-View Videos</papertitle>
			          </a>
			          <br>
                <strong>Fengkai Chen</strong>,
                <a>Feiyu Zhang</a>, 
                <a>Han Zheng</a>,
                <a>Zhuoting Han</a>
                <br>

			          <br>
			          <a href="data/Final_Report.pdf">PDF</a>
			          <p></p>
			          <p>Recent studies have witnessed the successes in applying deep learning approach 3D pose estimation. However, most of the 3D pose estimation models are either monocular or operating on single frames, which may not fully exploit the multi-view videos. To fill this gap, we propose a Bi-LSTM based 3D pose estimation model in multi-view videos, which can refine a 3D pose over an entire sequence from multi-view cameras. Our method outperforms the single frames-based model on dataset like Campus ‚Äì where we show quantitative improvements ‚Äì and successfully reconstruct 3D pose videos. By temporal refinement on single frames 3D poses, we effectively encode multi-view pose within a unified 3D framework. Furthermore, we propose a method to use temporal refinement module to improve the existing single frames-based 3D pose estimator. We show that our model can be extensive, which allows other deep learning-based models to retrain on previous estimated 3D pose following our paradigm.</p>
			        </td>
			      </tr>
						
          
					
					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://github.com/jonbarron/jonbarron_website">Reference</a>
                
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
