<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Fengkai Chen</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Fengkai Chen</name>
                <div class="site-affilation">
                  <span class="affilation"><ul class="flat">
              <p>I am an enthusiastic Autonomous Driving Simulation Engineer working in ADX Stellantis simulation team, and participate in the Stellantis-BMW group R&D project AutoDrive1.0. I graduated from University of Michigan, Ann Arbor at May.2023, and got my master of science degree in Electrical and Computer Engineer.
                <p>During my leisure time, I love snowboarding, videos games, cooking and watching movies.
                <div></div>

              <p style="text-align:center">
                <a href="data/Resume.pdf">Resume</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/fengkai-chen-901872212/">Linkedin</a> &nbsp/&nbsp
                <a href="https://github.com/FengkaiChen/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/JonBarron.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>


            <td style="padding:20px;width:100%;vertical-align:middle">
              <hr>
              <heading>Education Experience</heading>
              <p>
            	<div class="site-affilation">
                <span class="affilation"><ul class="flat">
                    <li class="name">Master of Science (M.Sc.) in Electrical and Computer Engineering (ECE), University of Michigan, Ann Arbor</li>
                    <li class="name">Bachelor of Engineering (B.Eng.) in Electrical Engineering (EE), Zhejiang University</li>
                    <li class="name">Bachelor of Science (B.Sc.) in Electrical Engineering (EE), University of Illinois, Urbana-Champaign </li>
                  </ul></span>
                </p>
              </div>
              <div class="row">
                <div class="column">
                  <img align="right"src="images/umich.png" alt="Umich" style="width:40%;vertical-align:middle">
                </div>
                <div class="column">
                  <img align="right"src="images/UIUC.png" alt="UIUC" style="width:40%">
                </div>
                <div class="column">
                  <img align="right"src="images/ZJU.png" alt="ZJU" style="width:40%">
                </div>
              </div>
              <br>
              <hr>
              <heading>Work Experience</heading>
              <br>
              <br>
              <div>
                <img src="images/stellantis.png" style="vertical-align:middle;" width="100">
                 <span><font size="4">ADAS Simulation Engineer</font>  <font size="2">(06/05/2023 - Present)</font></span>
             </div>
             <br>
                <li class="name">Working in ADX Stellantis simulation team, Stellantis-BMW Group Autonomous Driving R&D project Autodrive 1.0 /
                  Thunder.</li>
                <li class="name">Designing the vehicle model for Stellantis vehicles and integrating them into the simulation pipeline.</li>
                <li class="name">Developing OEM-specific SIL solutions for the simulation, and design of L2/L2+ features.</li>
                <li class="name">Validating features and components in CI/CD pipeline.</li>
            <div>
              <div>
                    <img src="images/isuzu.png" style="vertical-align:middle;" width="100">
                     <span><font size="4">Advanced Engineer Intern</font>  <font size="2">(02/03/2023 - 05/01/2023)</font></span>
                 </div>
                <li class="name">Integrate autonomous driving software stack with simulation software.</li>
                <li class="name">Validate and correlate between simulation and testing.</li>
                <li class="name">Support virtual development and CI/CD Jenkins pipeline building.</li>

                <div>
                  <img src="images/zhongheng.jpeg" style="vertical-align:middle;" width="100">
                   <span><font size="4">Hardware Engineer Intern</font>  <font size="2">(06/01/2020 - 08/31/2020)</font></span>
               </div>
              <li class="name">Carried out the design and test of power monitor product.</li>
              <li class="name">Validate the I/O waveform and ripple tex.</li>
              <li class="name">Fullfilled EMC tests on product comminication board.</li>
              <br>
              <hr>
              <heading>Research & Projects</heading>
              <br>
              <br>
              <div>
                My research interest lies in mobile robotics, machine learning, deep learning and computer vision. Most of my research is about robotics and deep learning for computer vision.
              <div>
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="malle_stop()" onmouseover="malle_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:40%;vertical-align:middle">
              <div class="one">
                <div class="two" id='malle_image'>
                  <img src='images/fig3.png' width="300"></div>
                <img src='images/husky.png' width="300">
              </div>
              <script type="text/javascript">
                function malle_start() {
                  document.getElementById('malle_image').style.opacity = "1";
                }

                function malle_stop() {
                  document.getElementById('malle_image').style.opacity = "0";
                }
                malle_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a>
                <papertitle>Ranking Inversement Learning & Incrementally-exploring Information Gathering</papertitle>
              </a>
              <br>
              <strong>Fengkai Chen</strong>,
              <a>Sangli Teng</a>,
              <a>Maani Ghaffari</a>
              <p></p>
              <p>
                Information gathering is an critical and broadly studied task for mobile robotics operating in unknown environments. Incrementally-exploring information Gathering(IIG) algorithm takes a dense stochastic map of enviroment to collect information for exploration. While the information gathering process is time-consuming and unstable, we proposed a new information collect method which apply Inverse Reinforcement Learning(IRL). The IRL  incorporates both exteroceptive and proprioceptive sensory data, and generate a reward map  to replace original information of IIG exploration. The IRL will be trained on human demonstration in advance, and the inference process is sufficiently efficient.
              </p>
            </td>
          </tr>
					
          <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:40%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfsuper_image'><video  width=190% height=190% muted autoplay loop>
                <source src="images/garage_garage_short.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/Intro.png' width="300">
              </div>
              <script type="text/javascript">
                function nerfsuper_start() {
                  document.getElementById('nerfsuper_image').style.opacity = "1";
                }

                function nerfsuper_stop() {
                  document.getElementById('nerfsuper_image').style.opacity = "0";
                }
                nerfsuper_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a>
                <papertitle>Online Map Recognition using Bayesian Updates</papertitle>
              </a>
              <br> 
              <strong>Fengkai Chen</strong>,
              <a>Jake Olkin</a>, 
              <a>Cameron Kisailus</a>,
              <a>Tianyang Shi</a>,
              <a>Sihang Wei</a>
              <br>

							<a href="data/Online Map Recognition using Bayesian Updates.pdf">PDF</a> / 
							<a href="https://www.youtube.com/watch?v=pzFOLR6G_VE&t=142s">video</a> /
							<a href="https://github.com/camkisailus/ROB530_FinalProject">code</a> / 
							<a href="https://colab.research.google.com/drive/1jvaOu-FcIKEyTYHuewVoGX_3eTZra149">colab</a>				
              <p></p>
              <p>In order to reliably deploy robots in large-scale environments, it is fundamental for robots to have accurate localization. Robot relocalization is the act of determining the position in a robot in a previously mapped environment. Relocalization in small-scale environments is usually done by maintaining a contiguous map of the entire environment, but this does not scale. Methods to combat this scaling problem have proposed splitting large, global maps into smaller metrical maps. However, this adds another dimension to the relocalization problem, since the algorithm must additionally determine which map is it located on. Probabilistic localization algorithms are governed by the total law of probability, so it is impossible to indicate low, or even zero, belief a robot is anywhere on a given map (i.e. a particle filter will always maintain some belief of the robot location)</p>
            </td>
          </tr>

          <tr onmouseout="p_stop()" onmouseover="p_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:40%;vertical-align:middle">
              <div class="one">
                <div class="two" id='project3'>
                  <img src='images/fig2.png' width="300"></div>
                <img src='images/fig4.png' width="300">
              </div>
              <script type="text/javascript">
                function p_start() {
                  document.getElementById('project3').style.opacity = "1";
                }

                function p_stop() {
                  document.getElementById('project3').style.opacity = "0";
                }
                p_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
			          <a>
			            <papertitle>3D Human Pose Detection and Estimation in Multi-View Videos</papertitle>
			          </a>
			          <br>
                <strong>Fengkai Chen</strong>,
                <a>Feiyu Zhang</a>, 
                <a>Han Zheng</a>,
                <a>Zhuoting Han</a>
                <br>

			          <br>
			          <a href="data/Final_Report.pdf">PDF</a>
			          <p></p>
			          <p>Recent studies have witnessed the successes in applying deep learning approach 3D pose estimation. However, most of the 3D pose estimation models are either monocular or operating on single frames, which may not fully exploit the multi-view videos. To fill this gap, we propose a Bi-LSTM based 3D pose estimation model in multi-view videos, which can refine a 3D pose over an entire sequence from multi-view cameras. Our method outperforms the single frames-based model on dataset like Campus ‚Äì where we show quantitative improvements ‚Äì and successfully reconstruct 3D pose videos. By temporal refinement on single frames 3D poses, we effectively encode multi-view pose within a unified 3D framework. Furthermore, we propose a method to use temporal refinement module to improve the existing single frames-based 3D pose estimator. We show that our model can be extensive, which allows other deep learning-based models to retrain on previous estimated 3D pose following our paradigm.</p>
			        </td>
			      </tr>
						
          
					
					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://github.com/jonbarron/jonbarron_website">Reference</a>
                
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
